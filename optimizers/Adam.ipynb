{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc802084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class Adam(optim.Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        super(Adam, self).__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = closure() if closure is not None else None\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            lr, betas, eps, weight_decay = group['lr'], group['betas'], group['eps'], group['weight_decay']\n",
    "            beta1, beta2 = betas\n",
    "\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "                grad = param.grad.data\n",
    "\n",
    "                if weight_decay != 0:\n",
    "                    grad = grad.add(weight_decay, param.data)\n",
    "\n",
    "                state = self.state[param]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['first_moment'] = torch.zeros_like(param.data)\n",
    "                    state['second_moment'] = torch.zeros_like(param.data)\n",
    "\n",
    "                first_moment, second_moment = state['first_moment'], state['second_moment']\n",
    "                state['step'] += 1\n",
    "\n",
    "                first_moment.mul_(beta1).add_(1 - beta1, grad)\n",
    "                second_moment.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "\n",
    "                momentum_bias_correction1 = 1 - beta1 ** state['step']\n",
    "                momentum_bias_correction2 = 1 - beta2 ** state['step']\n",
    "\n",
    "                step_size = lr * math.sqrt(momentum_bias_correction2) / momentum_bias_correction1\n",
    "\n",
    "                denom = second_moment.sqrt().add_(eps)\n",
    "                param.data.addcdiv_(-step_size, first_moment, denom)\n",
    "\n",
    "        return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Updated)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
